{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redcap import Project\n",
    "import pandas as pd\n",
    "\n",
    "#REDCap API configuration\n",
    "api_url = 'https://ruff.mrc.gm:8443/redcap/api/'\n",
    "api_key = '63A451E2DA73C4D6A4C64A17B36B9565'\n",
    "project = Project(api_url, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extract all data from Maternal Supplementation.\n",
    "MS_data = project.export_records(forms=['maternal_supplementation'])\n",
    "\n",
    "#convert data to Dataframe.\n",
    "MatSup_data=pd.DataFrame(MS_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extract all data from Randomization.\n",
    "Rand_data = project.export_records(forms=['randomization'])\n",
    "\n",
    "#convert data to Dataframe.\n",
    "Rand_data=pd.DataFrame(Rand_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Rand_data=Rand_data[['con_participantid_q1','redcap_event_name','ran_date','rnd_arm']]\n",
    "Rand=pd.DataFrame(Rand_data)\n",
    "\n",
    "\n",
    "#st_date as a date data type\n",
    "Rand_data['ran_date'] = pd.to_datetime(Rand_data['ran_date'], errors='coerce')\n",
    "\n",
    "\n",
    "rnd_data = Rand_data[\n",
    "    (Rand['redcap_event_name'] == 'week_20_arm_1') &\n",
    "    (Rand_data['rnd_arm']!=\"\")\n",
    "]\n",
    "\n",
    "rnd_data=pd.DataFrame(rnd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomization group mapping\n",
    "rnd_group = {\n",
    "'1':'B',\n",
    "'2':'N',\n",
    "'3':'P',\n",
    "'4':'A',\n",
    "'5':'X',\n",
    "'6':'Y',\n",
    "'7':'C',\n",
    "'8':'U',\n",
    "'9':'E',\n",
    "'10':'K',\n",
    "'11':'J',\n",
    "'12':'H',\n",
    "'13':'W',\n",
    "'14':'T',\n",
    "'15':'L'\n",
    "}\n",
    "rnd_data['rnd_arm'] = rnd_data['rnd_arm'].map(rnd_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_data=pd.DataFrame(rnd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['con_participantid_q1', 'infantid', 'del_ddate_q7', 'end_date',\n",
      "       'ran_date', 'rnd_arm', 'redcap_event_name'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#export infant ID\n",
    "inf_dob = project.export_records(forms=['infantid', 'delivery'])\n",
    "\n",
    "# Extract infant delivery and infant data\n",
    "inf_dob = project.export_records(forms=['infantid', 'delivery'])\n",
    "inf_del = pd.DataFrame(inf_dob)\n",
    "\n",
    "# Select relevant columns\n",
    "inf_data = inf_del[['con_participantid_q1', 'infantid', 'del_ddate_q7']]\n",
    "df_infant = pd.DataFrame(inf_data)\n",
    "\n",
    "# Convert delivery date to datetime data type\n",
    "df_infant['del_ddate_q7'] = pd.to_datetime(df_infant['del_ddate_q7'], errors='coerce')\n",
    "\n",
    "# Calculate supplementation end date\n",
    "df_infant['end_date'] = df_infant['del_ddate_q7'] + pd.DateOffset(months=6)\n",
    "\n",
    "# Assuming rnd_data is already defined and contains the columns 'con_participantid_q1', 'ran_date', and 'rnd_arm'\n",
    "Rand1=rnd_data[['con_participantid_q1','ran_date','rnd_arm','redcap_event_name']]\n",
    "# Merge df_infant with rnd_data to filter only the rows with minimum instances\n",
    "Randomized_part = pd.merge( df_infant,Rand1, on=['con_participantid_q1'] , how='inner')\n",
    "\n",
    "# Select relevant columns from the merged dataframe\n",
    "randomised = Randomized_part[['con_participantid_q1', 'infantid', 'ran_date', 'rnd_arm', 'del_ddate_q7', 'end_date']]\n",
    "randomised=randomised.drop_duplicates()\n",
    "\n",
    "# Print the columns of the merged dataframe\n",
    "print(Randomized_part.columns)\n",
    "\n",
    "randomised_df = pd.DataFrame({\n",
    "    'Participant ID':randomised['con_participantid_q1'],\n",
    "    'Infant ID': randomised['infantid'],\n",
    "    'Randomization date': randomised['ran_date'],\n",
    "    'Randomization Arm': randomised['rnd_arm'],\n",
    "    'Infant DoB': randomised['del_ddate_q7'],\n",
    "    'Supplement end date': randomised['end_date'],\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "randomised_df.to_csv('Supplementaton report.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the fields you want to extract based on logic\n",
    "MS_1_dataT = MatSup_data[['con_participantid_q1', 'redcap_event_name', 'redcap_repeat_instrument', 'redcap_repeat_instance', 'ms_dvisit_q1','ms_datetaken', 'ms_sup_administered_q2']]\n",
    "MS_1_dataT = pd.DataFrame(MS_1_dataT)\n",
    "\n",
    "# Convert 'ms_datetaken' and 'ms_dvisit_q1' to date data type\n",
    "MS_1_dataT['ms_datetaken'] = pd.to_datetime(MS_1_dataT['ms_datetaken'], errors='coerce')\n",
    "MS_1_dataT['ms_dvisit_q1'] = pd.to_datetime(MS_1_dataT['ms_dvisit_q1'], errors='coerce')\n",
    "\n",
    "# Filter out rows where 'redcap_repeat_instance' is an empty string\n",
    "MS_1_dataT = MS_1_dataT[MS_1_dataT['redcap_repeat_instance'] != '']\n",
    "\n",
    "# Convert 'redcap_repeat_instance' to integer type\n",
    "MS_1_dataT['redcap_repeat_instance'] = MS_1_dataT['redcap_repeat_instance'].astype(int)\n",
    "\n",
    "# Find the minimum instance number for each ID\n",
    "min_instancesT = MS_1_dataT.groupby('con_participantid_q1')['redcap_repeat_instance'].min().reset_index()\n",
    "\n",
    "# Merge min_instancesT with MS_1_dataT to filter only the rows with minimum instances\n",
    "MS_first_instanceT = pd.merge(MS_1_dataT, min_instancesT, on=['con_participantid_q1', 'redcap_repeat_instance'], how='inner')\n",
    "\n",
    "MS_first_instanceT = pd.DataFrame(MS_first_instanceT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the fields you want to extract base on logics.\n",
    "MS_data=MatSup_data[['con_participantid_q1','redcap_event_name','redcap_repeat_instrument','ms_sup_administered_q2','ms_reason_not_admin_q2a','ms_takenafterfast','ms_datetaken','ms_completed_by']]\n",
    "MS_data=pd.DataFrame(MS_data)\n",
    "\n",
    "#st_date as a date data type\n",
    "MS_data['hrf_date'] = pd.to_datetime(MS_data['ms_datetaken'], errors='coerce')\n",
    "\n",
    "\n",
    "MS_taken = MS_data[\n",
    "    (MS_data['ms_sup_administered_q2']==\"1\") |\n",
    "    (MS_data['ms_takenafterfast']==\"1\")\n",
    "]\n",
    "\n",
    "MS_taken=pd.DataFrame(MS_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    con_participantid_q1  total_ms_taken\n",
      "0              IN-M-001E             317\n",
      "1              IN-M-002H             292\n",
      "2              IN-M-004F             306\n",
      "3              IN-M-005J             307\n",
      "4              IN-M-007A             258\n",
      "..                   ...             ...\n",
      "241            IN-M-415L              10\n",
      "242            IN-M-416K              30\n",
      "243            IN-M-418C               9\n",
      "244            IN-M-441F               7\n",
      "245            IN-M-452K               2\n",
      "\n",
      "[246 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "##SUM OF ALL IP CONSUMED BY EACH PARTICIPANT\n",
    "MS_taken=pd.DataFrame(MS_taken)\n",
    "\n",
    "# Group by 'participantID' and count the occurrences\n",
    "sum_ms_taken = MS_taken.groupby('con_participantid_q1').size().reset_index(name='total_ms_taken')\n",
    "\n",
    "print(sum_ms_taken)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS_not_taken = MS_data[\n",
    "    ((MS_data['ms_sup_administered_q2']==\"0\") & (MS_data['ms_reason_not_admin_q2a']!=\"6\")) |\n",
    "    ((MS_data['ms_reason_not_admin_q2a']==\"6\") & (MS_data['ms_takenafterfast']==\"0\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUM OF ALL THE MISSED IP'S FOR EACH PARTICIPANT\n",
    "ms_not_taken=pd.DataFrame(MS_not_taken)\n",
    "\n",
    "# Group by 'participantID' and count the occurrences\n",
    "sum_ms_not_taken = ms_not_taken.groupby('con_participantid_q1').size().reset_index(name='total_ms_not_taken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##MERGE ALL NECESSARY DATAFRAME FOR THE FINAL REPORT\n",
    "#merge infant_data to delivery_data base on participant ID\n",
    "rand_supp = rnd_data.merge (sum_ms_taken, on='con_participantid_q1', how='left')\n",
    "\n",
    "#Merge the two DataFrames on 'con_participant_id' column\n",
    "ms_rnd_merged = rand_supp.merge(sum_ms_not_taken, on='con_participantid_q1', how='left')\n",
    "\n",
    "#Merge the two DataFrames on 'con_participant_id' column\n",
    "ms_rnd_merged = ms_rnd_merged.merge(MS_first_instanceT, on='con_participantid_q1', how='left')\n",
    "\n",
    "# Select the desired columns\n",
    "ms_rnd_log = ms_rnd_merged[['con_participantid_q1','rnd_arm','ms_dvisit_q1','total_ms_taken', 'total_ms_not_taken']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP_log = pd.DataFrame({\n",
    "    'Participant ID':ms_rnd_log['con_participantid_q1'],\n",
    "    'Randomization Arm': ms_rnd_log['rnd_arm'],\n",
    "    'First visit date': ms_rnd_log['ms_dvisit_q1'],\n",
    "    'IP Consumed': ms_rnd_log['total_ms_taken'],\n",
    "    'IP Not Consumed': ms_rnd_log['total_ms_not_taken'],\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "IP_log.to_csv('IP Log.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
