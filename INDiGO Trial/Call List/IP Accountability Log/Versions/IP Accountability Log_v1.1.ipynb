{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- The current version is V1.1\n",
    "#-- This is updated from v1.0 to V1.1\n",
    "#-- The updated version is a refactored code of the previous version, and including the biographic data of the participants.\n",
    "#-- Updated by Yusupha Ceesay on 29/07/2024\n",
    "#-- Implemented on 01/08/2024\n",
    "#-------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redcap import Project\n",
    "import pandas as pd\n",
    "import datetime\n",
    "today=pd.Timestamp.today()\n",
    "\n",
    "#REDCap API configuration\n",
    "##project configuration function\n",
    "def project_configuration(api_url,api_key):\n",
    "    return Project(api_url,api_key)\n",
    "\n",
    "###indigo project configuration\n",
    "project = project_configuration('https://ruff.mrc.gm:8443/redcap/api/', '63A451E2DA73C4D6A4C64A17B36B9565')\n",
    "\n",
    "###Sensitization project configuration\n",
    "sen_project = project_configuration('https://redcap.mrc.gm:8443/redcap/api/','008DBC63CA736CB68A3949DEFE43CC5D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Village mapping\n",
    "village_mapping = {\n",
    "'001':'Dumbuto',\n",
    "'002':'Sankandi',\n",
    "'003':'Nioro Jattaba',\n",
    "'004':'Jattaba',\n",
    "'005':'Jiffarong',\n",
    "'006':'Bajana',\n",
    "'007':'Kuli Kunda',\n",
    "'008':'Jamaru',\n",
    "'009':'Brikamanding',\n",
    "'010':'Kantong Kunda',\n",
    "'011':'Jali',\n",
    "'013':'Manduar',\n",
    "'014':'Bang Kuling',\n",
    "'015':'Gissay',\n",
    "'016':'Tankular',\n",
    "'017':'Joli',\n",
    "'018':'Kuyang',\n",
    "'019':'Bantasu',\n",
    "'020':'Santamba',\n",
    "'021':'Missira',\n",
    "'022':'Taborangkoto',\n",
    "'023':'Burong',\n",
    "'024':'Jula Kunda',\n",
    "'025':'Karantaba',\n",
    "'026':'Mandina',\n",
    "'027':'Janneh Kunda',\n",
    "'028':'Kemoto',\n",
    "'029':'Keneba',\n",
    "'030':'Batelling',\n",
    "'031':'Sandeng',\n",
    "'032':'Wudeba',\n",
    "'034':'Kenokoto',\n",
    "'035':'Manari',\n",
    "'036':'Nineteen',\n",
    "'040':'WUROKANG',\n",
    "'041':'KWINELLA SANSANKONO',\n",
    "'042':'KWINELLA NIA KUNDA',\n",
    "'043':'TENDABA',\n",
    "'044':'BUMARR',\n",
    "'045':'BAMBAKO',\n",
    "'046':'KUNDONG MARIAYA',\n",
    "'047':'NEMA',\n",
    "'048':'KUNDANG NUMU KUNDA',\n",
    "'049':'KUNDANG FULA KUNDA',\n",
    "'050':'NEMA KUTA',\n",
    "'051':'JIRROFF',\n",
    "'052':'MADINA ANGALLEH',\n",
    "'053':'JATTA KUNDA',\n",
    "'054':'MANDINA CENTRAL',\n",
    "'055':'SARE SARJO',\n",
    "'056':'SIBETO',\n",
    "'057':'SARE NDALLA',\n",
    "'058':'TABANANI',\n",
    "'060':'WILLINGARA',\n",
    "'061':'SARE MAMUDU'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Function to process sensitization data\n",
    "# def process_sensitization_data(project,village_mapping):\n",
    "#     fields = ['in_kiang_number', 'in_name', 'in_age', 'in_village', 'in_compound', \n",
    "#         'in_eden_number', 'in_contact1', 'in_contact2', 'in_contact3', 'in_contact4', \n",
    "#         'in_outcome', 'in_study_number'\n",
    "#         ]\n",
    "#     #sen_log_data= export_records_to_df(project,['indigo_sensitisation'],fields)\n",
    "#     sen_log_data=project.export_records(forms=['indigo_sensitisation'])\n",
    "#     sen_log_data = sen_log_data[(sen_log_data['in_outcome']=='1') &\n",
    "#                                 (sen_log_data['in_kiang_number'].notnull()) &\n",
    "#                                 (sen_log_data['in_study_number'].notnull())\n",
    "#                                 ]\n",
    "#     sen_log_data=sen_log_data.rename(columns={'in_study_number': 'con_participantid_q1'})\n",
    "#     sen_log_data['in_village'] = sen_log_data['in_village'].map(village_mapping)\n",
    "\n",
    "#     return sen_log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to process sensitization data\n",
    "\n",
    "def process_sensitization_data(project, village_mapping):\n",
    "    fields = ['in_kiang_number', 'in_name', 'in_age', 'in_village', 'in_compound', \n",
    "              'in_eden_number', 'in_contact1', 'in_contact2', 'in_contact3', 'in_contact4', \n",
    "              'in_outcome', 'in_study_number']\n",
    "    \n",
    "    # Export records from the project\n",
    "    sen_log_data = project.export_records(forms=['indigo_sensitisation'])\n",
    "    \n",
    "    # Convert to DataFrame if necessary\n",
    "    if isinstance(sen_log_data, list):\n",
    "        sen_log_data = pd.DataFrame(sen_log_data)\n",
    "\n",
    "    # Filter the data\n",
    "    sen_log_data = sen_log_data[(sen_log_data['in_outcome'] == '1') &\n",
    "                                (sen_log_data['in_kiang_number'].notnull()) &\n",
    "                                (sen_log_data['in_study_number'].notnull())]\n",
    "    \n",
    "    # Rename columns\n",
    "    sen_log_data = sen_log_data.rename(columns={'in_study_number': 'con_participantid_q1'})\n",
    "    \n",
    "    # Map village names\n",
    "    sen_log_data['in_village'] = sen_log_data['in_village'].map(village_mapping)\n",
    "\n",
    "    return sen_log_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SENSITIZATION DATA\n",
    "sen_log_data=process_sensitization_data(sen_project,village_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuceesay\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract and convert data from Maternal Supplementation\n",
    "MS_data = project.export_records(forms=['maternal_supplementation'])\n",
    "MatSup_data = pd.DataFrame(MS_data)\n",
    "\n",
    "# Extract and convert data from Randomization\n",
    "Rand_data = project.export_records(forms=['randomization'])\n",
    "Rand_data = pd.DataFrame(Rand_data)\n",
    "\n",
    "# Select relevant columns and convert 'ran_date' to datetime\n",
    "Rand_data = Rand_data[['con_participantid_q1', 'redcap_event_name', 'ran_date', 'rnd_arm']]\n",
    "Rand_data['ran_date'] = pd.to_datetime(Rand_data['ran_date'], errors='coerce')\n",
    "\n",
    "# Filter and map randomization data\n",
    "rnd_group = {\n",
    "    '1': 'B', '2': 'N', '3': 'P', '4': 'A', '5': 'X', '6': 'Y',\n",
    "    '7': 'C', '8': 'U', '9': 'E', '10': 'K', '11': 'J', '12': 'H',\n",
    "    '13': 'W', '14': 'T', '15': 'L'\n",
    "}\n",
    "rnd_data = Rand_data[(Rand_data['redcap_event_name'] == 'week_20_arm_1') & (Rand_data['rnd_arm'] != \"\")]\n",
    "rnd_data['rnd_arm'] = rnd_data['rnd_arm'].map(rnd_group)\n",
    "\n",
    "# Export infant ID and delivery data\n",
    "#inf_dob = project.export_records(forms=['infantid', 'delivery'])\n",
    "#inf_del = pd.DataFrame(inf_dob)\n",
    "\n",
    "##Delivery Data\n",
    "inf_dob = project.export_records(forms=['delivery'])\n",
    "inf_del = pd.DataFrame(inf_dob)\n",
    "inf_del['del_ddate_q7']=pd.to_datetime(inf_del['del_ddate_q7'], errors='coerce')\n",
    "\n",
    "inf_del=inf_del[['con_participantid_q1','del_ddate_q7','redcap_event_name']]\n",
    "inf_del=inf_del[(inf_del['redcap_event_name']=='delivery__postpart_arm_1') &\n",
    "                        (inf_del['del_ddate_q7'].notnull())]\n",
    "\n",
    "##Infant ID data\n",
    "inf_dt= project.export_records(forms=['infantid'])\n",
    "inf_dt = pd.DataFrame(inf_dt)\n",
    "inf_dt=inf_dt[['con_participantid_q1', 'infantid','redcap_event_name']]\n",
    "inf_dt=inf_dt[(inf_dt['redcap_event_name']=='baby_check_arm_2')]\n",
    "##merge infant mother\n",
    "inf_momther_dob = pd.merge(inf_dt, inf_del, on='con_participantid_q1', how='inner')\n",
    "# Select and convert relevant columns\n",
    "inf_data = inf_momther_dob[['con_participantid_q1', 'infantid', 'del_ddate_q7']]\n",
    "df_infant = pd.DataFrame(inf_data)\n",
    "df_infant['del_ddate_q7'] = pd.to_datetime(df_infant['del_ddate_q7'], errors='coerce')\n",
    "df_infant['end_date'] = df_infant['del_ddate_q7'] + pd.DateOffset(months=6)\n",
    "\n",
    "# Merge and select relevant columns for randomization data\n",
    "Rand1 = rnd_data[['con_participantid_q1', 'ran_date', 'rnd_arm', 'redcap_event_name']]\n",
    "Randomized_part = pd.merge(df_infant, Rand1, on='con_participantid_q1', how='right')\n",
    "randomised = Randomized_part[['con_participantid_q1', 'infantid', 'ran_date', 'rnd_arm', 'del_ddate_q7', 'end_date']]\n",
    "\n",
    "##WITHDRAWALS\n",
    "#extract study termination data\n",
    "termination_data = project.export_records(forms=['study_termination'])\n",
    "term_data=pd.DataFrame(termination_data)\n",
    "df_withdrw=term_data[['con_participantid_q1','st_date','st_reason','redcap_event_name']]\n",
    "df_withdrw=pd.DataFrame(df_withdrw)\n",
    "\n",
    "df_withdrw['st_date'] = pd.to_datetime(df_withdrw['st_date'], errors='coerce')\n",
    "\n",
    "df_withdrawals = df_withdrw[\n",
    "    (df_withdrw['redcap_event_name'] == 'end_of_study_arm_1') &\n",
    "    (df_withdrw['st_date'].notnull())\n",
    "]\n",
    "\n",
    "\n",
    "## EXCLUDE ALL WITHDRAWALS FROM THE DATA\n",
    "\n",
    "# Merge the dataframes on 'participant_id'\n",
    "ran_con_merged_df = pd.merge(randomised, df_withdrawals, on= 'con_participantid_q1', how='inner')\n",
    "\n",
    "# Filter out the common participant IDs\n",
    "randomised= randomised[~randomised['con_participantid_q1'].isin(ran_con_merged_df['con_participantid_q1'])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create DataFrame for randomised data and save to CSV\n",
    "# randomised_df = pd.DataFrame({\n",
    "#     'Participant ID': randomised['con_participantid_q1'],\n",
    "#     'Infant ID': randomised['infantid'],\n",
    "#     'Randomization date': randomised['ran_date'],\n",
    "#     'Randomization Arm': randomised['rnd_arm'],\n",
    "#     'Infant DoB': randomised['del_ddate_q7'],\n",
    "#     'Supplementation end date': randomised['end_date'],\n",
    "# })\n",
    "# randomised_df.to_csv('Supplementation_reportT.csv', index=False)\n",
    "\n",
    "# # Extract and convert data from Maternal Supplementation\n",
    "# MS_1_dataT = MatSup_data[['con_participantid_q1', 'redcap_event_name', 'redcap_repeat_instrument', 'redcap_repeat_instance', 'ms_dvisit_q1', 'ms_datetaken', 'ms_sup_administered_q2']]\n",
    "# MS_1_dataT['ms_datetaken'] = pd.to_datetime(MS_1_dataT['ms_datetaken'], errors='coerce')\n",
    "# MS_1_dataT['ms_dvisit_q1'] = pd.to_datetime(MS_1_dataT['ms_dvisit_q1'], errors='coerce')\n",
    "# MS_1_dataT = MS_1_dataT[MS_1_dataT['redcap_repeat_instance'] != '']\n",
    "# MS_1_dataT['redcap_repeat_instance'] = MS_1_dataT['redcap_repeat_instance'].astype(int)\n",
    "\n",
    "# # Find the minimum instance number for each ID and merge with the data\n",
    "# min_instancesT = MS_1_dataT.groupby('con_participantid_q1')['redcap_repeat_instance'].min().reset_index()\n",
    "# MS_first_instanceT = pd.merge(MS_1_dataT, min_instancesT, on=['con_participantid_q1', 'redcap_repeat_instance'], how='inner')\n",
    "\n",
    "# # Select and convert relevant columns for Maternal Supplementation data\n",
    "# MS_data = MatSup_data[['con_participantid_q1', 'redcap_event_name', 'redcap_repeat_instrument', 'ms_sup_administered_q2', 'ms_reason_not_admin_q2a', 'ms_takenafterfast', 'ms_datetaken', 'ms_completed_by']]\n",
    "# MS_data['ms_datetaken'] = pd.to_datetime(MS_data['ms_datetaken'], errors='coerce')\n",
    "\n",
    "# # Filter data based on supplementation taken\n",
    "# MS_taken = MS_data[(MS_data['ms_sup_administered_q2'] == \"1\") | (MS_data['ms_takenafterfast'] == \"1\")]\n",
    "\n",
    "# # Calculate the sum of all IP consumed by each participant\n",
    "# sum_ms_taken = MS_taken.groupby('con_participantid_q1').size().reset_index(name='total_ms_taken')\n",
    "\n",
    "# # Filter data based on supplementation not taken\n",
    "# MS_not_taken = MS_data[((MS_data['ms_sup_administered_q2'] == \"0\") & (MS_data['ms_reason_not_admin_q2a'] != \"6\")) | ((MS_data['ms_reason_not_admin_q2a'] == \"6\") & (MS_data['ms_takenafterfast'] == \"0\"))]\n",
    "\n",
    "# # Calculate the sum of all missed IPs for each participant\n",
    "# sum_ms_not_taken = MS_not_taken.groupby('con_participantid_q1').size().reset_index(name='total_ms_not_taken')\n",
    "\n",
    "# # Merge necessary dataframes for the final report\n",
    "# rand_supp = rnd_data.merge(sum_ms_taken, on='con_participantid_q1', how='left')\n",
    "# ms_rnd_merged = rand_supp.merge(sum_ms_not_taken, on='con_participantid_q1', how='left')\n",
    "# ms_rnd_merged = ms_rnd_merged.merge(MS_first_instanceT, on='con_participantid_q1', how='left')\n",
    "\n",
    "# # Select and create DataFrame for the IP log and save to CSV\n",
    "# ms_rnd_log = ms_rnd_merged[['con_participantid_q1', 'rnd_arm', 'ms_dvisit_q1', 'total_ms_taken', 'total_ms_not_taken']]\n",
    "# IP_log = pd.DataFrame({\n",
    "#     'Participant ID': ms_rnd_log['con_participantid_q1'],\n",
    "#     'Randomization Arm': ms_rnd_log['rnd_arm'],\n",
    "#     'First visit date': ms_rnd_log['ms_dvisit_q1'],\n",
    "#     'IP Consumed': ms_rnd_log['total_ms_taken'],\n",
    "#     'IP Not Consumed': ms_rnd_log['total_ms_not_taken'],\n",
    "# })\n",
    "# IP_log.to_csv('IP_LogT.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge with sensitization data\n",
    "def merge_with_sensitization(sup_df, sensitization_df):\n",
    "    return pd.merge(sup_df, sensitization_df, on='con_participantid_q1', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with sensitization data\n",
    "df_randomised = merge_with_sensitization(randomised, sen_log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "randomised_part= pd.DataFrame({\n",
    "        'PARTICIPANT ID': df_randomised['con_participantid_q1'],\n",
    "        'INFANT ID': df_randomised['infantid'],\n",
    "        'KIANG NUMBER': df_randomised['in_kiang_number'],\n",
    "        'NAME': df_randomised['in_name'],\n",
    "        'VILLAGE': df_randomised['in_village'],\n",
    "        'COMPOUND': df_randomised['in_compound'],\n",
    "        'CONTACT1': df_randomised['in_contact1'],\n",
    "        'CONTACT2': df_randomised['in_contact2'],\n",
    "        'CONTACT3': df_randomised['in_contact3'],\n",
    "        'CONTACT4': df_randomised['in_contact4'],\n",
    "        'Randomization Date': df_randomised['ran_date'],\n",
    "        'Randomization Arm': df_randomised['rnd_arm'],\n",
    "       'Infant DoB': df_randomised['del_ddate_q7'],\n",
    "    'Supplementation end date': df_randomised['end_date'],\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save DataFrame to CSV with a timestamp\n",
    "def save_to_csv(df, base_filename):\n",
    "    now = datetime.datetime.now()\n",
    "    timestamp = now.strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'{base_filename}_{timestamp}.csv'\n",
    "    df.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the to a CSV file\n",
    "save_to_csv(randomised_part, 'SupplementatonReport_v1.1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
